#!/bin/bash

# Set up ner_chang90k train/dev/test data
export data_name="conll2003"
export raw_data_dir="$DATA_DIR"
export data_files=( "ner_chang90k.conll.train" "ner_chang90k.conll.dev" "ner_chang90k.conll.test" )
# todo get this number automagically
export max_sent_len=126
export process_script="$DILATED_CNN_NER_ROOT/src/tsv_to_tfrecords.py"

export data_dir="$processed_data_dir/$data_name-w$filter_width-$embeddings_name"

if [[ "$start_end" == "true" ]]; then
    export data_dir="$data_dir-start_end"
fi

if [[ "$predict_pad" == "true" ]]; then
    export data_dir="$data_dir-pred_pad"
fi

if [[ "$documents" == "true" ]]; then
    export data_dir="$data_dir-docs"
fi

export train_dir="$data_dir/train"
export dev_dir="$data_dir/dev"
export test_dir="$data_dir/test"

export maps_dir=$train_dir

export vocab_cutoff=4
export update_vocab_file="$DILATED_CNN_NER_ROOT/data/vocabs/${data_name}_cutoff_${vocab_cutoff}.txt"

# character embeddings
export char_dim=300
export char_tok_dim=50
export char_input_dropout=0.85
