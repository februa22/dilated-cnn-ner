#!/bin/bash

# Set up ner_chang90k train/dev/test data
export data_name="conll2003"
export raw_data_dir="$DATA_DIR"
export data_files=( "ner_chang90k.train.conll" "ner_chang90k.dev.conll" "ner_chang90k.test.conll" )
# todo get this number automagically
export max_sent_len=126
export process_script="$DILATED_CNN_NER_ROOT/src/tsv_to_tfrecords.py"

export data_dir="$processed_data_dir/$data_name-w$filter_width-$embeddings_name"

if [[ "$start_end" == "true" ]]; then
    export data_dir="$data_dir-start_end"
fi

if [[ "$predict_pad" == "true" ]]; then
    export data_dir="$data_dir-pred_pad"
fi

if [[ "$documents" == "true" ]]; then
    export data_dir="$data_dir-docs"
fi

export train_dir="$data_dir/train"
export dev_dir="$data_dir/dev"
export test_dir="$data_dir/test"

export maps_dir=$train_dir

export vocab_cutoff=4
export update_vocab_file="$DILATED_CNN_NER_ROOT/data/vocabs/${data_name}_cutoff_${vocab_cutoff}.txt"
